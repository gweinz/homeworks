{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets = []\n",
    "with open(\"Gamergate.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        tweet = json.loads(line)\n",
    "\n",
    "        tweets.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_map = {}\n",
    "G = nx.DiGraph()\n",
    "for t in tweets:\n",
    "    if 'quoted_status_id_str' not in t:\n",
    "        usr = t['user']['screen_name']\n",
    "        G.add_node(usr)\n",
    "\n",
    "        if 'retweeted_status' in t:\n",
    "\n",
    "            rt = t['retweeted_status']['user']['screen_name']\n",
    "\n",
    "            if (usr, rt) in weight_map:\n",
    "                weight_map[(usr, rt)] += 1\n",
    "\n",
    "            else:\n",
    "                weight_map[(usr, rt)] = 1\n",
    "\n",
    "            G.add_edge(usr, rt, weight = weight_map[(usr, rt)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G, \"g.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges 48545\n",
      "Number of nodes 21414\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of edges\", G.number_of_edges())\n",
    "print(\"Number of nodes\", G.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max retweeted ChrisWarcraft\n",
      "Max retweeter SomeKindaBoogin\n",
      "4189\n",
      "1054\n"
     ]
    }
   ],
   "source": [
    "max_edge = -1\n",
    "max_node = ''\n",
    "end = ''\n",
    "\n",
    "outgoing = {}\n",
    "incoming = {}\n",
    "\n",
    "for u, v, weight in G.edges(data=\"weight\"):\n",
    "    if weight is not None:\n",
    "        \n",
    "        if u in outgoing:\n",
    "            outgoing[u] += weight\n",
    "        else:\n",
    "            outgoing[u] = weight\n",
    "            \n",
    "        if v in incoming:\n",
    "            incoming[v] += weight\n",
    "        else:\n",
    "            incoming[v] = weight\n",
    "        \n",
    "        if weight > max_edge:\n",
    "            max_edge = weight\n",
    "            max_node = u\n",
    "            end = v\n",
    "            \n",
    "print(\"Max retweeted\", max(incoming, key=incoming.get))\n",
    "print(\"Max retweeter\", max(outgoing, key=outgoing.get))\n",
    "print(G.in_degree('ChrisWarcraft', weight='weight'))\n",
    "print(G.out_degree('SomeKindaBoogin', weight='weight'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini = []\n",
    "with open(\"toy_test/mini_mid_gamergate.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        tweet = json.loads(line)\n",
    "\n",
    "        mini.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_to_remove(G):\n",
    "    \n",
    "    all_edges = nx.edge_betweenness_centrality(G, weight='weight')\n",
    " \n",
    "    for key, value in sorted(all_edges.items(), key=lambda item: item[1], reverse = True):\n",
    " \n",
    "        maxx = value\n",
    "        break\n",
    "        \n",
    "    edges=[]\n",
    "    for key, value in sorted(all_edges.items(), key=lambda item: item[1], reverse = True):\n",
    "        if value == maxx:\n",
    "            edges.append(key)\n",
    "            \n",
    "        else:\n",
    "            break\n",
    "        \n",
    "            \n",
    "    return edges\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "def girvan_newman(G, OG):\n",
    "    \n",
    "\n",
    "    splits = nx.number_connected_components(G)\n",
    "    edges = G.number_of_edges()\n",
    "    max_mod = -100\n",
    "    \n",
    "    while(edges > 1):\n",
    "        \n",
    "        \n",
    "        print('edges left', edges)\n",
    "        to_remove = edge_to_remove(G)\n",
    "        \n",
    "        for t in to_remove:\n",
    "            G.remove_edge(t[0], t[1])\n",
    "        \n",
    "        edges = G.number_of_edges()\n",
    "        \n",
    "            \n",
    "       \n",
    "        old_splits = splits\n",
    "        splits = nx.number_connected_components(G)\n",
    "        \n",
    "        \n",
    "        if old_splits != splits:\n",
    "            print('components', splits)\n",
    "            \n",
    "            modularity = get_modularity(G, OG)\n",
    "           \n",
    "        \n",
    "            if modularity > max_mod:\n",
    "                \n",
    "                \n",
    "                max_mod = modularity\n",
    "                print('new max mod:', max_mod)\n",
    "                nx.write_gexf(G, \"graph.gexf\")\n",
    "                id_splits = splits\n",
    "                partitions = list(nx.connected_components(G))\n",
    "        \n",
    "    return partitions, max_mod, id_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modularity(G, OG):\n",
    "    M = OG.size('weight')\n",
    "    cumulative_modularity = 0\n",
    "\n",
    "    partitions = nx.connected_components(G)\n",
    "    \n",
    "    for parts in partitions:\n",
    "        part_modularity = 0\n",
    "\n",
    "        for i in parts:\n",
    "            for j in parts:\n",
    "                \n",
    "                if i != j:\n",
    "                    \n",
    "                    ki = OG.degree(i, weight='weight')\n",
    "                    kj = OG.degree(j, weight='weight')\n",
    "                    \n",
    "                    A_bool = G.has_edge(i,j)\n",
    "\n",
    "                    if A_bool:\n",
    "                        Aij = G[i][j]['weight']\n",
    "                    else:\n",
    "                        Aij = 0\n",
    "                    \n",
    "                    rh = (ki*kj)/(2*M)\n",
    "                    tmp_modularity = Aij - rh\n",
    "                    \n",
    "                    \n",
    "                    part_modularity += tmp_modularity\n",
    "                    \n",
    "        \n",
    "        cumulative_modularity += part_modularity\n",
    "          \n",
    "    return cumulative_modularity/(2*M)    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_map = {}\n",
    "tweet_map = {}\n",
    "G = nx.Graph()\n",
    "OG = nx.Graph()\n",
    "for t in mini:\n",
    "    val = True\n",
    "    if val:\n",
    "        usr = t['user']['screen_name']\n",
    "        text = t['text']\n",
    "        if usr in tweet_map:\n",
    "            tweet_map[usr] += ' ' + text\n",
    "        else:\n",
    "            tweet_map[usr] = text\n",
    "        G.add_node(usr)\n",
    "        OG.add_node(usr)\n",
    "        if 'retweeted_status' in t:\n",
    "\n",
    "            rt = t['retweeted_status']['user']['screen_name']\n",
    "            \n",
    "            rtext = t['retweeted_status']['text']\n",
    "            if rt in tweet_map:\n",
    "                tweet_map[rt] += ' ' + rtext\n",
    "                tweet_map[usr] += ' ' + rtext\n",
    "            else:\n",
    "                tweet_map[rt] = rtext\n",
    "                tweet_map[usr] = rtext\n",
    "\n",
    "            if (usr, rt) in weight_map:\n",
    "                weight_map[(usr, rt)] += 1\n",
    "\n",
    "            else:\n",
    "                weight_map[(usr, rt)] = 1\n",
    "\n",
    "            G.add_edge(usr, rt, weight = weight_map[(usr, rt)])\n",
    "            OG.add_edge(usr, rt, weight = weight_map[(usr, rt)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges left 976\n",
      "components 431\n",
      "new max mod: 0.46334002010368114\n",
      "edges left 975\n",
      "edges left 974\n",
      "edges left 973\n",
      "edges left 972\n",
      "edges left 971\n",
      "edges left 970\n",
      "components 432\n",
      "new max mod: 0.46951503913091314\n",
      "edges left 969\n",
      "edges left 968\n",
      "edges left 967\n",
      "edges left 966\n",
      "edges left 965\n",
      "edges left 964\n",
      "edges left 963\n",
      "edges left 962\n",
      "edges left 961\n",
      "edges left 960\n",
      "edges left 959\n",
      "edges left 958\n",
      "edges left 957\n",
      "edges left 956\n",
      "edges left 955\n",
      "edges left 954\n",
      "edges left 953\n",
      "edges left 952\n",
      "edges left 951\n",
      "edges left 950\n",
      "edges left 949\n",
      "edges left 948\n",
      "edges left 947\n",
      "edges left 946\n",
      "edges left 945\n",
      "edges left 944\n",
      "edges left 943\n",
      "edges left 942\n",
      "edges left 941\n",
      "edges left 940\n",
      "edges left 939\n",
      "edges left 938\n",
      "edges left 937\n",
      "edges left 936\n",
      "edges left 935\n",
      "edges left 934\n",
      "edges left 933\n",
      "edges left 932\n",
      "edges left 931\n",
      "edges left 930\n",
      "edges left 929\n",
      "edges left 928\n",
      "edges left 927\n",
      "edges left 926\n",
      "edges left 925\n",
      "edges left 924\n",
      "edges left 923\n",
      "edges left 922\n",
      "edges left 921\n",
      "edges left 920\n",
      "edges left 919\n",
      "edges left 918\n",
      "components 433\n",
      "new max mod: 0.49031725980137114\n",
      "edges left 917\n",
      "edges left 916\n",
      "edges left 915\n",
      "edges left 914\n",
      "edges left 913\n",
      "edges left 912\n",
      "edges left 911\n",
      "edges left 910\n",
      "edges left 909\n",
      "edges left 908\n",
      "edges left 907\n",
      "edges left 906\n",
      "edges left 905\n",
      "components 434\n",
      "new max mod: 0.5175298877719723\n",
      "edges left 904\n",
      "edges left 903\n",
      "edges left 902\n",
      "edges left 901\n",
      "edges left 900\n",
      "edges left 899\n",
      "edges left 898\n",
      "edges left 897\n",
      "edges left 896\n",
      "components 435\n",
      "new max mod: 0.5670111181726661\n",
      "edges left 895\n",
      "edges left 894\n",
      "edges left 893\n",
      "edges left 892\n",
      "edges left 891\n",
      "edges left 890\n",
      "edges left 889\n",
      "edges left 888\n",
      "edges left 887\n",
      "edges left 886\n",
      "edges left 885\n",
      "edges left 884\n",
      "edges left 883\n",
      "edges left 882\n",
      "edges left 881\n",
      "edges left 880\n",
      "edges left 879\n",
      "edges left 878\n",
      "edges left 877\n",
      "edges left 876\n",
      "edges left 875\n",
      "edges left 874\n",
      "edges left 873\n",
      "edges left 872\n",
      "edges left 871\n",
      "edges left 870\n",
      "edges left 869\n",
      "edges left 868\n",
      "edges left 867\n",
      "edges left 866\n",
      "edges left 865\n",
      "edges left 864\n",
      "edges left 863\n",
      "edges left 862\n",
      "edges left 861\n",
      "edges left 860\n",
      "edges left 859\n",
      "edges left 858\n",
      "edges left 857\n",
      "edges left 856\n",
      "edges left 855\n",
      "components 436\n",
      "new max mod: 0.644269908399037\n",
      "edges left 854\n",
      "edges left 853\n",
      "edges left 852\n",
      "edges left 851\n",
      "edges left 850\n",
      "edges left 849\n",
      "edges left 848\n",
      "edges left 847\n",
      "edges left 846\n",
      "edges left 845\n",
      "edges left 844\n",
      "edges left 843\n",
      "edges left 842\n",
      "components 437\n",
      "new max mod: 0.6560406297594902\n",
      "edges left 841\n",
      "edges left 840\n",
      "edges left 839\n",
      "edges left 838\n",
      "edges left 837\n",
      "edges left 836\n",
      "edges left 835\n",
      "edges left 834\n",
      "edges left 833\n",
      "edges left 832\n",
      "edges left 831\n",
      "edges left 830\n",
      "edges left 829\n",
      "edges left 828\n",
      "edges left 827\n",
      "components 438\n",
      "new max mod: 0.7116672377011831\n",
      "edges left 826\n",
      "edges left 825\n",
      "edges left 824\n",
      "edges left 823\n",
      "edges left 822\n",
      "edges left 821\n",
      "components 439\n",
      "new max mod: 0.7208055335424015\n",
      "edges left 820\n",
      "edges left 819\n",
      "components 440\n",
      "new max mod: 0.7235988077148199\n",
      "edges left 818\n",
      "components 441\n",
      "new max mod: 0.7249427003917184\n",
      "edges left 817\n",
      "edges left 816\n",
      "edges left 815\n",
      "components 442\n",
      "edges left 813\n",
      "edges left 812\n",
      "components 443\n",
      "edges left 811\n",
      "edges left 810\n",
      "components 444\n",
      "edges left 809\n",
      "edges left 808\n",
      "edges left 807\n",
      "edges left 806\n",
      "components 445\n",
      "new max mod: 0.7253437322641589\n",
      "edges left 805\n",
      "edges left 804\n",
      "edges left 803\n",
      "edges left 802\n",
      "edges left 801\n",
      "edges left 800\n",
      "edges left 799\n",
      "edges left 798\n",
      "edges left 797\n",
      "edges left 796\n",
      "components 446\n",
      "new max mod: 0.7362744662135073\n",
      "edges left 795\n",
      "components 447\n",
      "new max mod: 0.7364854438507497\n",
      "edges left 794\n",
      "edges left 793\n",
      "components 448\n",
      "new max mod: 0.7391074076689509\n",
      "edges left 789\n",
      "edges left 788\n",
      "components 449\n",
      "edges left 787\n",
      "components 450\n",
      "edges left 786\n",
      "edges left 785\n",
      "edges left 784\n",
      "edges left 783\n",
      "edges left 782\n",
      "edges left 781\n",
      "edges left 780\n",
      "components 451\n",
      "new max mod: 0.7395293629434354\n",
      "edges left 779\n",
      "edges left 778\n",
      "edges left 777\n",
      "edges left 776\n",
      "edges left 775\n",
      "edges left 774\n",
      "components 452\n",
      "edges left 773\n",
      "edges left 772\n",
      "edges left 771\n",
      "components 453\n",
      "edges left 770\n",
      "edges left 769\n",
      "edges left 768\n",
      "components 454\n",
      "edges left 767\n",
      "edges left 766\n",
      "components 455\n",
      "edges left 765\n",
      "edges left 764\n",
      "edges left 763\n",
      "edges left 762\n",
      "edges left 761\n",
      "components 456\n",
      "edges left 760\n",
      "edges left 759\n",
      "components 457\n",
      "edges left 758\n",
      "edges left 757\n",
      "edges left 756\n",
      "edges left 754\n",
      "components 458\n",
      "edges left 753\n",
      "components 459\n",
      "edges left 752\n",
      "components 460\n",
      "edges left 751\n",
      "components 461\n",
      "edges left 750\n",
      "components 464\n",
      "edges left 747\n",
      "edges left 746\n",
      "components 465\n",
      "edges left 745\n",
      "edges left 744\n",
      "components 466\n",
      "edges left 743\n",
      "components 467\n",
      "edges left 742\n",
      "edges left 741\n",
      "components 468\n",
      "edges left 740\n",
      "edges left 739\n",
      "edges left 738\n",
      "components 469\n",
      "edges left 737\n",
      "components 471\n",
      "edges left 733\n",
      "components 473\n",
      "edges left 731\n",
      "edges left 730\n",
      "edges left 729\n",
      "edges left 728\n",
      "components 474\n",
      "edges left 727\n",
      "components 475\n",
      "edges left 726\n",
      "components 476\n",
      "edges left 725\n",
      "components 477\n",
      "edges left 723\n",
      "components 479\n",
      "edges left 721\n",
      "components 480\n",
      "edges left 720\n",
      "components 482\n",
      "edges left 718\n",
      "edges left 717\n",
      "edges left 716\n",
      "components 483\n",
      "edges left 715\n",
      "components 484\n",
      "edges left 714\n",
      "components 485\n",
      "edges left 712\n",
      "edges left 711\n",
      "components 486\n",
      "edges left 709\n",
      "components 487\n",
      "edges left 708\n",
      "components 537\n",
      "edges left 658\n",
      "components 586\n",
      "edges left 609\n",
      "components 588\n",
      "edges left 607\n",
      "edges left 606\n",
      "edges left 605\n",
      "edges left 604\n",
      "components 589\n",
      "edges left 603\n",
      "components 592\n",
      "edges left 600\n",
      "edges left 599\n",
      "components 593\n",
      "edges left 598\n",
      "components 595\n",
      "edges left 596\n",
      "components 596\n",
      "edges left 595\n",
      "components 598\n",
      "edges left 593\n",
      "edges left 592\n",
      "components 599\n",
      "edges left 591\n",
      "components 604\n",
      "edges left 586\n",
      "components 608\n",
      "edges left 582\n",
      "components 609\n",
      "edges left 581\n",
      "components 611\n",
      "edges left 578\n",
      "components 612\n",
      "edges left 577\n",
      "components 614\n",
      "edges left 575\n",
      "components 616\n",
      "edges left 573\n",
      "components 620\n",
      "edges left 569\n",
      "components 683\n",
      "edges left 506\n",
      "edges left 505\n",
      "components 684\n",
      "edges left 504\n",
      "components 688\n",
      "edges left 500\n",
      "components 703\n",
      "edges left 485\n",
      "components 727\n",
      "edges left 461\n",
      "components 753\n",
      "edges left 435\n",
      "components 775\n",
      "edges left 413\n",
      "components 777\n",
      "edges left 411\n",
      "components 780\n",
      "edges left 408\n",
      "edges left 407\n",
      "components 782\n",
      "edges left 405\n",
      "components 800\n",
      "edges left 387\n",
      "components 815\n",
      "edges left 371\n",
      "components 816\n",
      "edges left 370\n",
      "components 850\n",
      "edges left 336\n",
      "components 883\n",
      "edges left 303\n",
      "components 912\n",
      "edges left 274\n",
      "components 960\n",
      "edges left 226\n",
      "components 1060\n",
      "edges left 126\n",
      "components 1183\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-597-dee7eede3a71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgirvan_newman\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "grp, mod, comps = girvan_newman(G, OG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = nx.read_gexf('graph.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.number_connected_components(rg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp.sort(key=len)\n",
    "results = []\n",
    "for g in grp:\n",
    "    results.append(sorted(list(g)))\n",
    "\n",
    "rst = sorted(results, key=itemgetter(0))\n",
    "rst.sort(key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('listfile.txt', 'w') as filehandle:\n",
    "    filehandle.write(\"Best Modularity is: \" + str(mod) + '\\n')\n",
    "    filehandle.writelines(\"%s\\n\" % str(place)[1:-1].replace(\" \", \"\") for place in rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tweet_map = {}\n",
    "\n",
    "for t in mini:\n",
    "    val = True\n",
    "    if val:\n",
    "        usr = t['user']['screen_name']\n",
    "        text = t['text']\n",
    "        if usr in tweet_map:\n",
    "            tweet_map[usr] += ' ' + text\n",
    "        else:\n",
    "            tweet_map[usr] = text\n",
    "    \n",
    "        if 'retweeted_status' in t:\n",
    "\n",
    "            rt = t['retweeted_status']['user']['screen_name']\n",
    "            \n",
    "            rtext = t['retweeted_status']['text']\n",
    "            if rt in tweet_map:\n",
    "                tweet_map[rt] += ' ' + rtext\n",
    "\n",
    "            else:\n",
    "                tweet_map[rt] = rtext\n",
    "               \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_comm = rst[-2:]\n",
    "rest = rst[:-2]\n",
    "arr = []\n",
    "\n",
    "cluster = 1\n",
    "for k in k_comm:\n",
    "    for usr in k:\n",
    "        tweet = tweet_map[usr]\n",
    "            \n",
    "        bit = (usr, tweet, cluster)\n",
    "        arr.append(bit)\n",
    "    cluster -=1\n",
    "\n",
    "df = pd.DataFrame(arr, columns=['user', 'tweet', 'community'])\n",
    "train_len = len(df)\n",
    "\n",
    "arr = []\n",
    "\n",
    "for k in rest:\n",
    "    for usr in k:\n",
    "        tweet = tweet_map[usr]\n",
    "\n",
    "        bit = (usr, tweet, -1)\n",
    "        arr.append(bit)\n",
    "df2 = pd.DataFrame(arr, columns=['user', 'tweet', 'community'])\n",
    "df = df.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[:train_len]\n",
    "test = df[train_len:]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "features_train = train['tweet']\n",
    "labels_train = train['community']\n",
    "features_test = test['tweet']\n",
    "labels_test = test['community']\n",
    "\n",
    "features_train = vectorizer.fit_transform(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(features_train, labels_train)\n",
    "score_train = clf.score(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/griffinweinhold/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/griffinweinhold/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "features_test = vectorizer.transform(features_test)\n",
    "preds = clf.predict(features_test)\n",
    "test['community'] = preds\n",
    "train['community'] = clf.predict(features_train)\n",
    "final = test.append(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_map = {}\n",
    "results_map[0] = []\n",
    "results_map[1] = []\n",
    "\n",
    "for index, row in final.iterrows():\n",
    "    results_map[row['community']].append(row['user'])\n",
    "\n",
    "with open(\"task2_B.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for com in results_map:\n",
    "        result = results_map[com]\n",
    "        push = sorted(result)\n",
    "        f.write(\"%s\\n\" % str(push)[1:-1].replace(\" \", \"\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = {}\n",
    "real[0] = []\n",
    "real[1] = []\n",
    "with open(\"toy_test/task2_B.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    ct = 0\n",
    "    for line in f.readlines():\n",
    "        word = ''\n",
    "        for l in line:\n",
    "            if l == ',':\n",
    "                real[ct].append(word[1:-1])\n",
    "                word = ''\n",
    "            else:\n",
    "                word+=l\n",
    "               \n",
    "        ct+=1\n",
    "pred = {}\n",
    "pred[0] = []\n",
    "pred[1] = []\n",
    "with open(\"task2_B.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    ct = 0\n",
    "    for line in f.readlines():\n",
    "        word = ''\n",
    "        for l in line:\n",
    "            if l == ',':\n",
    "                pred[ct].append(word[1:-1])\n",
    "                word = ''\n",
    "            else:\n",
    "                word+=l\n",
    "               \n",
    "        ct+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216\n",
      "965\n"
     ]
    }
   ],
   "source": [
    "for p in pred:\n",
    "    print(len(pred[p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216\n",
      "965\n"
     ]
    }
   ],
   "source": [
    "for r in real:\n",
    "    print(len(real[r]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = train['tweet']\n",
    "labels_train = train['community']\n",
    "X_train_counts = count_vect.fit_transform(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(X_train_counts, labels_train)\n",
    "clf.score(X_train_counts, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_counts = count_vect.transform(test['tweet'])\n",
    "\n",
    "#do the predictions\n",
    "preds = clf.predict(X_new_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/griffinweinhold/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/griffinweinhold/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test['community'] = preds\n",
    "train['community'] = clf.predict(X_train_counts)\n",
    "final = test.append(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_map = {}\n",
    "results_map[0] = []\n",
    "results_map[1] = []\n",
    "\n",
    "for index, row in final.iterrows():\n",
    "    results_map[row['community']].append(row['user'])\n",
    "\n",
    "with open(\"task2_C.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for com in results_map:\n",
    "        result = results_map[com]\n",
    "        push = sorted(result)\n",
    "        f.write(\"%s\\n\" % str(push)[1:-1].replace(\" \", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = {}\n",
    "real[0] = []\n",
    "real[1] = []\n",
    "with open(\"toy_test/task2_C.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    ct = 0\n",
    "    for line in f.readlines():\n",
    "        word = ''\n",
    "        for l in line:\n",
    "            if l == ',':\n",
    "                real[ct].append(word[1:-1])\n",
    "                word = ''\n",
    "            else:\n",
    "                word+=l\n",
    "               \n",
    "        ct+=1\n",
    "pred = {}\n",
    "pred[0] = []\n",
    "pred[1] = []\n",
    "with open(\"task2_C.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    ct = 0\n",
    "    for line in f.readlines():\n",
    "        word = ''\n",
    "        for l in line:\n",
    "            if l == ',':\n",
    "                pred[ct].append(word[1:-1])\n",
    "                word = ''\n",
    "            else:\n",
    "                word+=l\n",
    "               \n",
    "        ct+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n",
      "1029\n"
     ]
    }
   ],
   "source": [
    "for p in pred:\n",
    "    print(len(pred[p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n",
      "1029\n"
     ]
    }
   ],
   "source": [
    "for r in real:\n",
    "    print(len(real[r]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
